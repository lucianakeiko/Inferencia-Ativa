<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>> 3 O caminho para a inferência ativa | Inferencia Ativa</title>
  <meta name="description" content="O Princípio da Energia Livre na Mente, Cérebro e Comportamento." />
  <meta name="generator" content="bookdown 0.26 and GitBook 2.6.7" />

  <meta property="og:title" content="> 3 O caminho para a inferência ativa | Inferencia Ativa" />
  <meta property="og:type" content="book" />
  <meta property="og:image" content="/images/Figura_1_1.png" />
  <meta property="og:description" content="O Princípio da Energia Livre na Mente, Cérebro e Comportamento." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="> 3 O caminho para a inferência ativa | Inferencia Ativa" />
  
  <meta name="twitter:description" content="O Princípio da Energia Livre na Mente, Cérebro e Comportamento." />
  <meta name="twitter:image" content="/images/Figura_1_1.png" />

<meta name="author" content="Thomas Parr, Giovanni Pezzulo, and Karl J. Friston" />


<meta name="date" content="2022-06-07" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="o-caminho-de-baixo-para-a-inferência-ativa.html"/>
<link rel="next" href="dicionário.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>




<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Inferencia Ativa</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Conteúdo</a></li>
<li class="chapter" data-level="" data-path="prefácio.html"><a href="prefácio.html"><i class="fa fa-check"></i>Prefácio</a></li>
<li class="chapter" data-level="1" data-path="visão-geral.html"><a href="visão-geral.html"><i class="fa fa-check"></i><b>1</b> Visão Geral</a>
<ul>
<li class="chapter" data-level="1.1" data-path="visão-geral.html"><a href="visão-geral.html#introdução"><i class="fa fa-check"></i><b>1.1</b> Introdução</a></li>
<li class="chapter" data-level="1.2" data-path="visão-geral.html"><a href="visão-geral.html#como-os-organismos-vivos-persistem-e-agem-adaptativamente"><i class="fa fa-check"></i><b>1.2</b> Como os Organismos Vivos Persistem e Agem Adaptativamente?</a></li>
<li class="chapter" data-level="1.3" data-path="visão-geral.html"><a href="visão-geral.html#inferência-ativa-comportamento-a-partir-dos-primeiros-princípios"><i class="fa fa-check"></i><b>1.3</b> Inferência Ativa: Comportamento a partir dos Primeiros Princípios</a></li>
<li class="chapter" data-level="1.4" data-path="visão-geral.html"><a href="visão-geral.html#estrutura-do-livro"><i class="fa fa-check"></i><b>1.4</b> Estrutura do Livro</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="visão-geral.html"><a href="visão-geral.html#parte-1-inferência-ativa-na-teoria"><i class="fa fa-check"></i><b>1.4.1</b> Parte 1: Inferência Ativa na Teoria</a></li>
<li class="chapter" data-level="1.4.2" data-path="visão-geral.html"><a href="visão-geral.html#parte-2-inferência-ativa-na-prática"><i class="fa fa-check"></i><b>1.4.2</b> Parte 2: Inferência Ativa na Prática</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="visão-geral.html"><a href="visão-geral.html#resumo"><i class="fa fa-check"></i><b>1.5</b> Resumo</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="o-caminho-de-baixo-para-a-inferência-ativa.html"><a href="o-caminho-de-baixo-para-a-inferência-ativa.html"><i class="fa fa-check"></i><b>2</b> O Caminho de baixo para a Inferência Ativa</a>
<ul>
<li class="chapter" data-level="2.1" data-path="o-caminho-de-baixo-para-a-inferência-ativa.html"><a href="o-caminho-de-baixo-para-a-inferência-ativa.html#introdução-1"><i class="fa fa-check"></i><b>2.1</b> Introdução</a></li>
<li class="chapter" data-level="2.2" data-path="o-caminho-de-baixo-para-a-inferência-ativa.html"><a href="o-caminho-de-baixo-para-a-inferência-ativa.html#percepção-como-inferência"><i class="fa fa-check"></i><b>2.2</b> Percepção como Inferência</a></li>
<li class="chapter" data-level="2.3" data-path="o-caminho-de-baixo-para-a-inferência-ativa.html"><a href="o-caminho-de-baixo-para-a-inferência-ativa.html#inferência-biológica-e-otimização"><i class="fa fa-check"></i><b>2.3</b> Inferência Biológica e Otimização</a></li>
<li class="chapter" data-level="2.4" data-path="o-caminho-de-baixo-para-a-inferência-ativa.html"><a href="o-caminho-de-baixo-para-a-inferência-ativa.html#ação-como-inferência"><i class="fa fa-check"></i><b>2.4</b> Ação como Inferência</a></li>
<li class="chapter" data-level="2.5" data-path="o-caminho-de-baixo-para-a-inferência-ativa.html"><a href="o-caminho-de-baixo-para-a-inferência-ativa.html#minimizando-a-discrepância-entre-o-modelo-e-o-mundo"><i class="fa fa-check"></i><b>2.5</b> Minimizando a discrepância entre o modelo e o mundo</a></li>
<li class="chapter" data-level="2.6" data-path="o-caminho-de-baixo-para-a-inferência-ativa.html"><a href="o-caminho-de-baixo-para-a-inferência-ativa.html#minimizando-a-energia-livre-variacional"><i class="fa fa-check"></i><b>2.6</b> Minimizando a Energia Livre Variacional</a></li>
<li class="chapter" data-level="2.7" data-path="o-caminho-de-baixo-para-a-inferência-ativa.html"><a href="o-caminho-de-baixo-para-a-inferência-ativa.html#energia-livre-esperada-e-planejamento-como-inferência"><i class="fa fa-check"></i><b>2.7</b> Energia Livre Esperada e Planejamento como Inferência</a></li>
<li class="chapter" data-level="2.8" data-path="o-caminho-de-baixo-para-a-inferência-ativa.html"><a href="o-caminho-de-baixo-para-a-inferência-ativa.html#o-que-é-energia-livre-esperada"><i class="fa fa-check"></i><b>2.8</b> O que é energia livre esperada?</a></li>
<li class="chapter" data-level="2.9" data-path="o-caminho-de-baixo-para-a-inferência-ativa.html"><a href="o-caminho-de-baixo-para-a-inferência-ativa.html#no-final-da-estrada-baixa"><i class="fa fa-check"></i><b>2.9</b> No final da estrada baixa</a></li>
<li class="chapter" data-level="2.10" data-path="o-caminho-de-baixo-para-a-inferência-ativa.html"><a href="o-caminho-de-baixo-para-a-inferência-ativa.html#resumo-1"><i class="fa fa-check"></i><b>2.10</b> Resumo</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="o-caminho-para-a-inferência-ativa.html"><a href="o-caminho-para-a-inferência-ativa.html"><i class="fa fa-check"></i><b>3</b> O caminho para a inferência ativa</a>
<ul>
<li class="chapter" data-level="3.1" data-path="o-caminho-para-a-inferência-ativa.html"><a href="o-caminho-para-a-inferência-ativa.html#introdução-2"><i class="fa fa-check"></i><b>3.1</b> Introdução</a></li>
<li class="chapter" data-level="3.2" data-path="o-caminho-para-a-inferência-ativa.html"><a href="o-caminho-para-a-inferência-ativa.html#envoltórios-de-markov"><i class="fa fa-check"></i><b>3.2</b> Envoltórios de Markov</a></li>
<li class="chapter" data-level="3.3" data-path="o-caminho-para-a-inferência-ativa.html"><a href="o-caminho-para-a-inferência-ativa.html#minimização-de-surpresa-e-auto-evidência"><i class="fa fa-check"></i><b>3.3</b> Minimização de surpresa e auto-evidência</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="o-caminho-para-a-inferência-ativa.html"><a href="o-caminho-para-a-inferência-ativa.html#minimização-de-surpresa-como-um-princípio-hamiltoniano-de-menor-ação"><i class="fa fa-check"></i><b>3.3.1</b> Minimização de surpresa como um princípio hamiltoniano de menor ação</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="o-caminho-para-a-inferência-ativa.html"><a href="o-caminho-para-a-inferência-ativa.html#relações-entre-inferência-cognição-e-dinâmica-estocástica"><i class="fa fa-check"></i><b>3.4</b> Relações entre Inferência, Cognição e Dinâmica Estocástica</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="o-caminho-para-a-inferência-ativa.html"><a href="o-caminho-para-a-inferência-ativa.html#energia-livre-variacional-evidência-modelo-e-surpresa"><i class="fa fa-check"></i><b>3.4.1</b> Energia Livre Variacional, Evidência Modelo e Surpresa</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="dicionário.html"><a href="dicionário.html"><i class="fa fa-check"></i>Dicionário</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Inferencia Ativa</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="o-caminho-para-a-inferência-ativa" class="section level1 hasAnchor" number="3">
<h1><span class="header-section-number">> 3</span> O caminho para a inferência ativa<a href="o-caminho-para-a-inferência-ativa.html#o-caminho-para-a-inferência-ativa" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Máquinas de sobrevivência que podem simular o futuro estão um salto à frente das máquinas de sobrevivência que só podem aprender com base em tentativa e erro evidentes. O problema com o julgamento aberto é que leva tempo e energia. O problema com o erro evidente é que muitas vezes é fatal. A simulação é mais segura e mais rápida.
—Richard Dawkins</p>
<div id="introdução-2" class="section level2 hasAnchor" number="3.1">
<h2><span class="header-section-number">3.1</span> Introdução<a href="o-caminho-para-a-inferência-ativa.html#introdução-2" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>No capítulo 2, motivamos a introdução da energia livre como meio de realizar inferência Bayesiana aproximada (ou seja, o caminho inferior para a Inferência Ativa). Aqui, introduzimos a energia livre de outra perspectiva, a da estrada principal, que inverte esse raciocínio: ela parte dos primeiros princípios da física estatística e do imperativo central de que os organismos devem manter sua existência - ou seja, evitar estados surpreendentes - e então introduz a minimização da energia livre como uma solução computacionalmente tratável para este problema. O capítulo revela a equivalência formal entre a minimização da energia livre variacional e a maximização da evidência do modelo (ou auto-evidência) em inferência Bayesiana aproximada, revelando uma conexão entre energia livre e perspectivas Bayesianas em sistemas adaptativos. Finalmente, discute como a Inferência Ativa fornece uma nova perspectiva de primeiro princípio para entender o comportamento (ótimo).</p>
<p>A Inferência Ativa é uma teoria de como os organismos vivos mantêm sua existência minimizando a surpresa – ou um substituto tratável para surpreender, energia livre variacional – via percepção e ação. Partindo dos primeiros princípios, avança um novo esquema baseado em crenças para entender o comportamento e a cognição, que tem inúmeras implicações empíricas.</p>
<p>O caminho para a Inferência Ativa parte da premissa de que, para sobreviver, qualquer organismo vivo precisa se manter em um conjunto adequado de estados preferidos, evitando outros estados não preferidos do ambiente. Esses estados preferidos são definidos em primeiro lugar por adaptações evolutivas específicas de nicho. No entanto, como veremos mais tarde, em organismos avançados, isso também pode se estender a objetivos cognitivos aprendidos. Por exemplo, para sobreviver, um peixe tem que ficar em uma zona de conforto que corresponde a um pequeno subconjunto de todos os estados possíveis do universo: tem que ficar na água. Da mesma forma, um ser humano precisa garantir que seus estados internos (por exemplo, variáveis ​​fisiológicas como temperatura corporal e frequência cardíaca) permaneçam sempre dentro de faixas aceitáveis ​​- caso contrário, eles morrerão (ou, mais precisamente, se tornarão outra coisa, como um cadáver). Essa faixa aceitável ou zona de conforto define estipulativamente os estados característicos em que algo deve estar para ser essa coisa.</p>
<p>Os organismos vivos resolvem esse problema biológico fundamental exercendo controle ativo sobre seus estados (por exemplo, da temperatura corporal) em muitos níveis, que variam de mecanismos reguladores automáticos, como sudorese (fisiologia), a mecanismos cognitivos, como comprar e consumir uma bebida (psicologia). ) a práticas culturais como a distribuição de sistemas de ar condicionado (ciências sociais).</p>
<p>De uma perspectiva mais formal, a Inferência Ativa apresenta o problema biológico da – ou explicação para – a sobrevivência como minimização de surpresas. Essa formulação se baseia em uma definição técnica de estados surpreendentes da teoria da informação – essencialmente, estados surpreendentes indexam aqueles fora da zona de conforto dos organismos vivos. Em seguida, propõe a minimização da energia livre como uma maneira prática e biologicamente fundamentada para que organismos ou sistemas adaptativos minimizem a surpresa dos encontros sensoriais.</p>
</div>
<div id="envoltórios-de-markov" class="section level2 hasAnchor" number="3.2">
<h2><span class="header-section-number">3.2</span> Envoltórios de Markov<a href="o-caminho-para-a-inferência-ativa.html#envoltórios-de-markov" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Uma pré-condição importante para qualquer sistema adaptativo é que ele deve desfrutar de alguma separação e autonomia do ambiente – sem o qual ele simplesmente se dissiparia, dissolveria e, assim, sucumbiria à dinâmica ambiental. Na ausência dessa separação, não haveria surpresa a minimizar; deve haver algo para se surpreender e algo para se surpreender. Em outras palavras, há pelo menos duas coisas – sistema e ambiente – e elas podem ser desambiguações uma da outra. Uma maneira formal de expressar uma separação entre um sistema e o resto do ambiente é a construção estatística de um envoltório de Markov (Pearl 1988); ver quadro 3.1</p>
<table>
<colgroup>
<col width="100%" />
</colgroup>
<thead>
<tr class="header">
<th>quadro 3.1 Envoltórios de Markov</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Um envoltório de Markov é um importante conceito recorrente neste livro (Friston 2019a, Kirchhoff et al. 2018, Palacios et al. 2020). Tecnicamente, um envoltório (b) é definido da seguinte forma: <span class="math display">\[ \mu \perp x|b \Longleftrightarrow p(\mu, x|b) = p(\mu|b)p(x|b)\]</span> Isso diz (de duas maneiras diferentes, mas equivalentes) que uma variável μ é condicionalmente independente de uma variável x se b for conhecido. Em outras palavras, se conhecemos b, conhecer x não nos daria informações adicionais sobre μ. Um exemplo comum disso é uma cadeia de Markov, onde o passado causa o presente causa o futuro. Nesse cenário, o passado só pode influenciar o futuro por meio do presente. Isso significa que nenhuma informação adicional sobre o futuro é obtida descobrindo sobre o passado (assumindo que conhecemos o presente). Para identificar um envoltório de Markov em um sistema em que conhecemos as dependências condicionais, podemos seguir uma regra simples. O envoltório para uma determinada variável inclui seus pais (as variáveis das quais ela depende), seus filhos (as variáveis que dependem dela) e, em algumas configurações, os outros pais de seus filhos.</td>
</tr>
</tbody>
</table>
<p>Em resumo, um envoltório de Markov é o conjunto de variáveis que medeiam todas as interações (estatísticas) entre um sistema e seu ambiente. A Figura 3.1 ilustra uma interpretação de um envoltório de Markov em um cenário dinâmico. Aqui as independências condicionais foram complementadas com restrições dinâmicas, de modo que os fluxos não dependam de estados no lado oposto do envoltório.</p>
<p>O envoltório de Markov na figura 3.1 distingue estados internos ao sistema adaptativo (ou seja, atividade cerebral) de estados externos do ambiente. Além disso, identifica dois estados adicionais, estados sensoriais rotulados e estados ativos, que formam o envoltório que (estatisticamente) separa os estados internos e externos. A separação estatística significa que, se soubéssemos sobre os estados ativo e sensorial, os estados externos não ofereceriam informações adicionais sobre os estados internos (e vice-versa). Em uma configuração dinâmica, isso é frequentemente interpretado como dizendo que os estados internos não podem alterar diretamente os estados externos, mas podem fazê-lo vicariamente alterando os estados ativos. Da mesma forma, os estados externos não podem alterar diretamente os estados internos, mas podem fazê-lo indiretamente, alterando os estados sensoriais.</p>
<p>Esta é uma reafirmação do ciclo clássico de percepção de ação, em que um sistema adaptativo e seu ambiente podem interagir (apenas) por meio de ações e observações, respectivamente. Esta reformulação tem dois benefícios principais.</p>
<div class="figure">
<img src="images/Figura_3_1.png" alt="" />
<p class="caption"><strong>Figura 3.1</strong> Um envoltório de Markov dinâmico, que separa um sistema adaptativo (aqui, o cérebro) do ambiente. A dinâmica de cada conjunto de estados é determinada por um fluxo determinístico especificado como uma função <span class="math inline">\((f)\)</span> fornecendo a taxa média de variação e flutuações estocásticas adicionais (aleatórias) <span class="math inline">\((ω)\)</span>. As setas indicam a direção da influência de cada variável sobre as taxas de variação de outras variáveis (tecnicamente, os elementos não nulos dos jacobianos associados). Isso é apenas um exemplo; pode-se usar um envoltório de Markov para separar um organismo inteiro do ambiente ou aninhar vários envoltórios de Markov um dentro do outro. Por exemplo, cérebros, organismos, díades e comunidades podem ser concebidos em termos de diferentes envoltórios de Markov que estão aninhadas umas nas outras (veja Friston 2019a; Parr, Da Costa e Friston 2020 para um tratamento formal). Confusamente, campos diferentes usam notações diferentes para as variáveis; às vezes, os estados sensoriais são denotados por <span class="math inline">\(s\)</span>, estados externos <span class="math inline">\(η\)</span> e estados ativos <span class="math inline">\(a\)</span>. Aqui escolhemos variáveis para consistência com os outros capítulos deste livro.</p>
</div>
<p>Primeiro, formaliza o fato de que os estados internos de um sistema adaptativo são autônomos da dinâmica ambiental e, portanto, podem resistir às suas influências. Em segundo lugar, ela estrutura a maneira pela qual os sistemas adaptativos minimizam sua surpresa: destaca os estados internos, sensoriais e ativos aos quais eles têm acesso. Especificamente, a surpresa é definida em relação aos estados sensoriais, enquanto a dinâmica dos estados internos e ativos são os meios pelos quais a surpresa dos estados sensoriais pode ser minimizada.</p>
<p>O ponto-chave a ser observado aqui é que os estados internos de um sistema adaptativo têm uma relação formal com os estados externos. Isso se deve a um tipo de simetria em toda o envoltório de Markov, pois tanto influenciam quanto são influenciadas por estados do envoltório. Uma consequência disso é que podemos construir distribuições de probabilidade condicional para os estados internos e externos, dados os estados gerais. Como eles estão condicionados aos mesmos estados gerais, podemos associar pares de estados internos e externos esperados entre si. Em outras palavras, em média, os estados interno e externo adquirem uma espécie de sincronia (generalizada) – exatamente como poderíamos antecipar ao prender um pêndulo a cada extremidade de uma viga de madeira. Com o tempo, à medida que se sincronizam, cada pêndulo torna-se preditivo do outro através da influência vicária do feixe (Huygens 1673).</p>
<p>A Figura 3.2 oferece uma intuição gráfica para essa relação. Isso significa que, se pudermos escrever distribuições independentes sobre estados externos e internos, dado seu envoltório de Markov, os dois estados se tornarão informativos um sobre o outro por meio desse envoltório.</p>
<div class="figure">
<img src="images/Figura_3_2.png" alt="" />
<p class="caption">Figura 3.2 Associação entre estados internos médios de um envoltório de Markov e distribuições de estados externos. Topo: Assumindo uma forma gaussiana linear para as probabilidades condicionais, esses gráficos mostram amostras da distribuição condicional sobre estados externos e internos, respectivamente, dados estados gerais. As linhas pretas grossas indicam a média dessas variáveis, dado o estado do envoltório associado. Inferior esquerdo: Os mesmos dados são plotados para ilustrar a sincronização de estados internos e externos proporcionada pelo compartilhamento de um envoltório de Markov – aqui, uma sincronização inversa. As linhas tracejadas e a cruz preta ilustram que se conhecêssemos o estado médio interno (linha vertical), poderíamos identificar o estado médio externo (linha horizontal) e a dispersão em torno deste ponto. Inferior direito: Podemos associar o estado interno médio com uma distribuição sobre o estado externo.</p>
</div>
<p>Essa sincronia dá aos estados internos a aparência de representar (ou modelar) estados externos — o que remete à ideia de minimização da surpresa apresentada no capítulo 2. Isso porque a surpresa depende de um modelo interno de como os dados sensoriais são gerados. Para recapitular, minimizar a surpresa (probabilidade logarítmica negativa) de observações sensoriais torna-se idêntica a maximizar a evidência (probabilidade marginal) para o modelo, que é apenas a probabilidade de observações sensoriais sob esse modelo. Essa noção de minimização de surpresas pode ser entendida a partir de duas perspectivas equivalentes – bayesiana e de energia livre –, que discutiremos a seguir.</p>
</div>
<div id="minimização-de-surpresa-e-auto-evidência" class="section level2 hasAnchor" number="3.3">
<h2><span class="header-section-number">3.3</span> Minimização de surpresa e auto-evidência<a href="o-caminho-para-a-inferência-ativa.html#minimização-de-surpresa-e-auto-evidência" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Sob uma perspectiva bayesiana, um agente com um envoltório de Markov parece modelar o ambiente externo no sentido de que estados internos correspondem (em média) a uma representação probabilística – uma crença posterior aproximada – de estados externos do sistema (figura 3.2). A dinâmica dos estados internos corresponde a uma forma de inferência bayesiana (aproximada) de estados externos, pois seu movimento altera a distribuição de probabilidade associada, que é proporcionada por um modelo generativo implícito de como as sensações (ou estados sensoriais no jargão do envoltório de Markov) são gerados. Se restabelecermos a noção de um agente como constituído por estados internos e gerais, podemos falar sobre o modelo generativo de um agente.</p>
<p>É importante ressaltar que o modelo generativo do agente não pode simplesmente imitar a dinâmica externa (caso contrário, o agente simplesmente seguiria a dinâmica dissipativa externa). Em vez disso, o modelo também deve especificar as condições preferenciais para a existência do agente, ou as regiões de estados que o agente deve visitar para manter sua existência, ou satisfazer os critérios de sua existência em termos de ocupação de estados característicos. Esses estados preferidos (ou observações) podem ser especificados como os anteriores do modelo - o que implica que o modelo assume implicitamente que suas sensações preferidas (anteriores) são mais prováveis de ocorrer (ou seja, são menos surpreendentes) se satisfizer os critérios de existência . Isso significa que tem um viés de otimismo implícito. Esse viés de otimismo é necessário para que o agente vá além da mera duplicação de dinâmicas externas para prescrever estados ativos que subscrevem seus estados preferenciais ou característicos.</p>
<p>Sob essa formulação, pode-se definir o comportamento ótimo (com relação às preferências anteriores) como a maximização da evidência do modelo por percepção e ação. De fato, a evidência do modelo resume quão bem o modelo generativo se ajusta ou explica as sensações. Um bom ajuste indica que o modelo explica com sucesso suas sensações (este é o lado descritivo da inferência); ao mesmo tempo, realiza suas sensações preferidas, já que são menos surpreendentes (este é o lado prescritivo da inferência). Esse bom ajuste é uma garantia de minimização da surpresa, pois maximizar a evidência do modelo <span class="math inline">\(P( y)\)</span> é matematicamente equivalente a minimizar a surpresa: <span class="math inline">\(ℑ( y)  =  −ln P( y).\)</span></p>
<p>Uma forma de reformular os argumentos acima de forma mais sucinta consiste em dizer que qualquer sistema adaptativo se engaja em “auto-evidência” (Hohwy 2016). Autoevidenciar aqui significa agir para reunir dados sensoriais consistentes com (ou seja, que fornece evidência para) um modelo interno, maximizando assim a evidência do modelo.</p>
<div id="minimização-de-surpresa-como-um-princípio-hamiltoniano-de-menor-ação" class="section level3 hasAnchor" number="3.3.1">
<h3><span class="header-section-number">3.3.1</span> Minimização de surpresa como um princípio hamiltoniano de menor ação<a href="o-caminho-para-a-inferência-ativa.html#minimização-de-surpresa-como-um-princípio-hamiltoniano-de-menor-ação" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Nas seções anteriores, afirmamos que a surpresa deve ser minimizada, mas não detalhamos por que isso acontece. Embora os detalhes da física subjacente da autoevidência estejam fora do escopo deste livro (consulte Friston 2019b para obter detalhes), fornecemos aqui uma breve visão geral dos princípios. Estes são sustentados pela ideia de que criaturas biológicas – com envoltórios de Markov – persistem ao longo do tempo, resistindo aos efeitos dispersivos das flutuações ambientais. A persistência de uma envoltório de Markov implica que a distribuição de estados do envoltório permanece constante ao longo do tempo. Simplificando, isso significa que qualquer desvio de estados sensoriais (ou ativos) de regiões que são altamente prováveis ​​sob essa distribuição deve ser corrigido pelo fluxo médio de estados (que é apenas a parte determinística do fluxo na figura 3.1). Expressando isso como um físico poderia, sistemas estocásticos (aleatórios) em estado estacionário se envolvem em dinâmicas que (em média) descem uma função de energia (ou Hamiltoniana) que é interpretável como uma evidência de log negativo ou surpresa. Isso é como uma bola rolando morro abaixo de alta energia potencial gravitacional no topo da colina para baixa energia em uma bacia. Veja a figura 3.3.</p>
<p>Para o sistema mostrado à esquerda da figura 3.3, toda vez que uma flutuação causa um movimento para um estado menos provável, isso é corrigido por um movimento para cima no gradiente de probabilidade, de modo que o sistema ocupe regiões com densidade de probabilidade maior parte do tempo . O principal insight aqui é que esse sistema mantém os estados sensoriais dentro de uma faixa estreita, minimizando a surpresa (em média) – em contraste com o sistema da direita, para o qual a surpresa cresce indefinidamente.</p>
<div class="figure">
<img src="images/Figura_3_3.png" alt="" />
<p class="caption"><strong>Figura 3.3</strong> Esquerda: Caminho tomado por um sistema dinâmico aleatório bidimensional com um estado estacionário (não-equilíbrio <a href="#fn12" class="footnote-ref" id="fnref12"><sup>12</sup></a>). Isso pode ser interpretado como minimizando sua surpresa, que é mostrada no gráfico de contorno à direita. Direita: O centro é a região menos surpreendente; os círculos que se afastam do centro representam regiões progressivamente mais surpreendentes. Meio: Em contraste, este gráfico mostra a trajetória de um sistema começando no mesmo lugar (5, 5), com flutuações aleatórias de mesma amplitude, cuja dinâmica não guarda relação com surpresa. Não só entra em regiões mais surpreendentes do espaço; também não consegue atingir qualquer tipo de estado estacionário, dissipando-se de forma irrestrita ao longo do tempo. O escopo da Inferência Ativa é restrito a sistemas como o da esquerda – que contrariam flutuações aleatórias com seu fluxo médio e, assim, mantêm sua forma ao longo do tempo.</p>
</div>
<p>A minimização da surpresa permite que os organismos vivos resistam (temporariamente) à segunda lei da termodinâmica, que afirma que a entropia – ou a dispersão de estados sistêmicos – sempre cresce. Isso porque, em média, a entropia é a média de longo prazo da surpresa e, em média, a maximização de uma probabilidade logarítmica de observações é equivalente à minimização da entropia (Shannon) <a href="#fn13" class="footnote-ref" id="fnref13"><sup>13</sup></a></p>
<p><span class="math inline">\(H[P(y)]=\mathbb{E_{P(y)}[ℑ(y)]}=-\mathbb{E_{P(y)}[\ln P(y)]}\qquad\qquad\qquad (3.1)\)</span></p>
<p>Garantir que uma pequena proporção de estados sensoriais seja ocupada com alta probabilidade é equivalente a manter uma entropia particular. Essa é uma característica definidora dos sistemas auto-organizados, há muito reconhecida pelas teorias cibernéticas.</p>
<p>Do ponto de vista de um fisiologista, a minimização de surpresas formaliza a ideia de homeostase. À medida que um valor de sensor sai de sua faixa ideal, mecanismos de feedback negativo entram em ação que revertem esses desvios. De uma perspectiva de controle, podemos interpretar o comportamento ótimo em relação a alguma densidade de probabilidade de estado estacionário desejada. Em outras palavras, se definirmos uma distribuição de resultados preferidos, o comportamento ótimo envolverá a evolução do sistema em direção a essa distribuição e sua manutenção.</p>
<p>Como vimos no capítulo 2, a energia livre é um limite superior para a surpresa, sugerindo que o comportamento ótimo pode ser obtido minimizando a energia livre em face de flutuações aleatórias. Lembre-se de que a diferença entre energia livre e surpresa é a divergência entre uma probabilidade posterior exata (isto é, a distribuição de estados externos dados estados envoltórios) e uma probabilidade posterior aproximada (isto é, a distribuição sobre estados externos dados estados internos médios). Como tal, o movimento dos estados internos pode ser pensado como minimizando a divergência, o que permite que os estados ativos, em média, minimizem a surpresa que acompanha os estados sensoriais. Em outras palavras, o comportamento ótimo resultante da minimização da energia livre é aquele que é menos surpreendente e segue um caminho de menor Ação <a href="#fn14" class="footnote-ref" id="fnref14"><sup>14</sup></a> do estado atual para o estado desejado – ou seja, o princípio hamiltoniano de menor Ação aplicado ao comportamento .</p>
<p>A Figura 3.3 mostra um exemplo muito simples de um sistema equipado com um atrator aleatório. Isso é análogo a um termostato, que (no jargão cibernético) tem um único ponto de ajuste e não pode aprender ou planejar. A Inferência Ativa visa usar o mesmo aparato explicativo para cobrir sistemas muito mais complexos e adaptativos. Aqui, a diferença entre sistemas mais simples e mais complexos pode ser reduzida às diferentes formas de seus atratores – de pontos fixos a dinâmicas cada vez mais complexas e itinerantes. A partir dessa perspectiva, pode-se entender os organismos vivos como buscando constantemente um compromisso entre estabilidade excessiva e dispersão excessiva – e a Inferência Ativa visa explicar como esse compromisso é alcançado.</p>
</div>
</div>
<div id="relações-entre-inferência-cognição-e-dinâmica-estocástica" class="section level2 hasAnchor" number="3.4">
<h2><span class="header-section-number">3.4</span> Relações entre Inferência, Cognição e Dinâmica Estocástica<a href="o-caminho-para-a-inferência-ativa.html#relações-entre-inferência-cognição-e-dinâmica-estocástica" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>O físico E. T. Jaynes ficou famoso por argumentar que a inferência, a teoria da informação e a física estatística são perspectivas diferentes sobre a mesma coisa ( Jaynes 1957). Nas seções anteriores, discutimos como as perspectivas Bayesiana e da física estatística oferecem duas maneiras equivalentes de entender a minimização de surpresas e o comportamento ideal – adicionando efetivamente uma forma de cognição à tríade de Jaynes. Essa equivalência entre várias escolas de pensamento é atraente, mas pode ser confusa para quem não está familiarizado com os respectivos formalismos, onde muitas palavras diferentes são usadas para se referir às mesmas quantidades. Para ajudar a desmistificar isso, nesta seção elaboramos as principais equivalências entre as perspectivas Bayesiana e Física Estatística e suas interpretações cognitivas; veja a tabela 3.1 para um resumo e o quadro 3.2.</p>
<p><strong>Tabela 3.1</strong> Física estatística, inferência bayesiana e teoria da informação - e suas interpretações cognitivas</p>
<table>
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">Física estatística</th>
<th align="center">Inferência Bayesiana e Teoria da Informação</th>
<th align="center">Interpretação cognitiva</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Minimize a energia livre variacional</td>
<td align="center">Maximize a evidência do modelo (ou probabilidade marginal); minimizar a surpresa (ou auto-informação)</td>
<td align="center">Percepção e ação</td>
</tr>
<tr class="even">
<td align="center">Minimize a energia livre esperada; Hamiltoniano princípio da menor ação</td>
<td align="center">Inferir o curso de ação mais provável (ou menos surpreendente)</td>
<td align="center">Planejamento como inferência</td>
</tr>
<tr class="odd">
<td align="center">Atingir o estado estacionário de não equilíbrio</td>
<td align="center">Realizar inferência Bayesiana aproximada</td>
<td align="center">Auto-evidência</td>
</tr>
<tr class="even">
<td align="center">Fluxos de gradiente em funções de energia; gradiente descendente em energia livre</td>
<td align="center">Ascensão do gradiente na evidência do modelo; descida gradiente na surpresa</td>
<td align="center">Dinâmica neuronal</td>
</tr>
</tbody>
</table>
<table>
<colgroup>
<col width="100%" />
</colgroup>
<thead>
<tr class="header">
<th>Quadro 3.2 Energia livre em física estatística e inferência ativa</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>A noção de energia livre é amplamente utilizada em física estatística para caracterizar (por exemplo) sistemas termodinâmicos. Embora a Inferência Ativa use exatamente as mesmas equações, ela as aplica para caracterizar o estado de crença de um agente (em relação a um modelo generativo). Assim, quando falamos de um agente de Inferência Ativa minimizando sua energia livre (variacional), estamos nos referindo a processos que mudam seu estado de crença, não (por exemplo) as partículas de seu corpo. Para evitar mal-entendidos, usamos o termo energia livre variacional, adotando uma terminologia mais comum em aprendizado de máquina. Outro ponto mais sutil é que o conceito de energia livre é frequentemente usado no contexto da termodinâmica estatística de equilíbrio. A Inferência Ativa tem como alvo organismos vivos – ou sistemas de estado estacionário de não equilíbrio que são abertos – que apresentam trocas contínuas e recíprocas com o meio ambiente. Este é um campo de romance emocionante (Friston 2019a).</td>
</tr>
</tbody>
</table>
<div id="energia-livre-variacional-evidência-modelo-e-surpresa" class="section level3 hasAnchor" number="3.4.1">
<h3><span class="header-section-number">3.4.1</span> Energia Livre Variacional, Evidência Modelo e Surpresa<a href="o-caminho-para-a-inferência-ativa.html#energia-livre-variacional-evidência-modelo-e-surpresa" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Uma primeira equivalência importante é entre a maximização da evidência do modelo (ou probabilidade marginal) na inferência Bayesiana e a minimização da energia livre variacional – ambas minimizam a surpresa. Essa equivalência torna-se evidente quando se apela para uma solução aproximada específica para problemas intratáveis de inferência – inferência variacional. A inferência variacional reformula o problema de inferência como um problema de otimização minimizando a energia livre. O mínimo da energia livre é o ponto em que a aproximação da solução exata está no seu melhor. Expressar isso formalmente esclarece as relações entre as três quantidades:</p>

</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="12">
<li id="fn12"><p>Desequilíbrio aqui se refere à ausência de equilíbrio detalhado. O equilíbrio detalhado é a invariância de um sistema sob reversão no tempo, uma vez que atingiu o estado estacionário. Podemos ver que o sistema da esquerda da figura 3.3 não possui equilíbrio detalhado, pois a trajetória tende a se curvar no sentido anti-horário em torno dos contornos de surpresa. Se fôssemos reproduzir isso ao contrário, o sistema pareceria girar no sentido horário.<a href="o-caminho-para-a-inferência-ativa.html#fnref12" class="footnote-back">↩︎</a></p></li>
<li id="fn13"><p>Isso não é o mesmo que dizer que sistemas que minimizam surpresas devem minimizar sua entropia. Como vemos na figura 3.3, o sistema não tende a uma distribuição (ponto) infinitamente precisa que minimizaria a entropia, mas mantém uma dispersão consistente ao longo do tempo – limitando a entropia de cima e de baixo.<a href="o-caminho-para-a-inferência-ativa.html#fnref13" class="footnote-back">↩︎</a></p></li>
<li id="fn14"><p>O A maiúsculo é usado para distinguir Ação como uma integral de caminho de uma Lagrangiana da ação como a dinâmica dos estados ativos de um envoltório de Markov.<a href="o-caminho-para-a-inferência-ativa.html#fnref14" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="o-caminho-de-baixo-para-a-inferência-ativa.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="dicionário.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Inferencia Ativa.pdf", "Inferencia Ativa.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
