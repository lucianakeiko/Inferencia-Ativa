<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>> 2 O Caminho de baixo para a Inferência Ativa | Inferencia Ativa</title>
  <meta name="description" content="O Princípio da Energia Livre na Mente, Cérebro e Comportamento." />
  <meta name="generator" content="bookdown 0.26 and GitBook 2.6.7" />

  <meta property="og:title" content="> 2 O Caminho de baixo para a Inferência Ativa | Inferencia Ativa" />
  <meta property="og:type" content="book" />
  <meta property="og:image" content="/images/Figura_1_1.png" />
  <meta property="og:description" content="O Princípio da Energia Livre na Mente, Cérebro e Comportamento." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="> 2 O Caminho de baixo para a Inferência Ativa | Inferencia Ativa" />
  
  <meta name="twitter:description" content="O Princípio da Energia Livre na Mente, Cérebro e Comportamento." />
  <meta name="twitter:image" content="/images/Figura_1_1.png" />

<meta name="author" content="Thomas Parr, Giovanni Pezzulo, and Karl J. Friston" />


<meta name="date" content="2022-05-30" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="visão-geral.html"/>
<link rel="next" href="dicionário.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>




<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Inferencia Ativa</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Conteúdo</a></li>
<li class="chapter" data-level="" data-path="prefácio.html"><a href="prefácio.html"><i class="fa fa-check"></i>Prefácio</a></li>
<li class="chapter" data-level="1" data-path="visão-geral.html"><a href="visão-geral.html"><i class="fa fa-check"></i><b>1</b> Visão Geral</a>
<ul>
<li class="chapter" data-level="1.1" data-path="visão-geral.html"><a href="visão-geral.html#introdução"><i class="fa fa-check"></i><b>1.1</b> Introdução</a></li>
<li class="chapter" data-level="1.2" data-path="visão-geral.html"><a href="visão-geral.html#como-os-organismos-vivos-persistem-e-agem-adaptativamente"><i class="fa fa-check"></i><b>1.2</b> Como os Organismos Vivos Persistem e Agem Adaptativamente?</a></li>
<li class="chapter" data-level="1.3" data-path="visão-geral.html"><a href="visão-geral.html#inferência-ativa-comportamento-a-partir-dos-primeiros-princípios"><i class="fa fa-check"></i><b>1.3</b> Inferência Ativa: Comportamento a partir dos Primeiros Princípios</a></li>
<li class="chapter" data-level="1.4" data-path="visão-geral.html"><a href="visão-geral.html#estrutura-do-livro"><i class="fa fa-check"></i><b>1.4</b> Estrutura do Livro</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="visão-geral.html"><a href="visão-geral.html#parte-1-inferência-ativa-na-teoria"><i class="fa fa-check"></i><b>1.4.1</b> Parte 1: Inferência Ativa na Teoria</a></li>
<li class="chapter" data-level="1.4.2" data-path="visão-geral.html"><a href="visão-geral.html#parte-2-inferência-ativa-na-prática"><i class="fa fa-check"></i><b>1.4.2</b> Parte 2: Inferência Ativa na Prática</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="visão-geral.html"><a href="visão-geral.html#resumo"><i class="fa fa-check"></i><b>1.5</b> Resumo</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="o-caminho-de-baixo-para-a-inferência-ativa.html"><a href="o-caminho-de-baixo-para-a-inferência-ativa.html"><i class="fa fa-check"></i><b>2</b> O Caminho de baixo para a Inferência Ativa</a>
<ul>
<li class="chapter" data-level="2.1" data-path="o-caminho-de-baixo-para-a-inferência-ativa.html"><a href="o-caminho-de-baixo-para-a-inferência-ativa.html#introdução-1"><i class="fa fa-check"></i><b>2.1</b> Introdução</a></li>
<li class="chapter" data-level="2.2" data-path="o-caminho-de-baixo-para-a-inferência-ativa.html"><a href="o-caminho-de-baixo-para-a-inferência-ativa.html#percepção-como-inferência"><i class="fa fa-check"></i><b>2.2</b> Percepção como Inferência</a></li>
<li class="chapter" data-level="2.3" data-path="o-caminho-de-baixo-para-a-inferência-ativa.html"><a href="o-caminho-de-baixo-para-a-inferência-ativa.html#inferência-biológica-e-otimização"><i class="fa fa-check"></i><b>2.3</b> Inferência Biológica e Otimização</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="dicionário.html"><a href="dicionário.html"><i class="fa fa-check"></i>Dicionário</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Inferencia Ativa</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="o-caminho-de-baixo-para-a-inferência-ativa" class="section level1 hasAnchor" number="2">
<h1><span class="header-section-number">> 2</span> O Caminho de baixo para a Inferência Ativa<a href="o-caminho-de-baixo-para-a-inferência-ativa.html#o-caminho-de-baixo-para-a-inferência-ativa" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>My thinking is first and last and always for the sake of my ­doing. —­William James</p>
<div id="introdução-1" class="section level2 hasAnchor" number="2.1">
<h2><span class="header-section-number">2.1</span> Introdução<a href="o-caminho-de-baixo-para-a-inferência-ativa.html#introdução-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Este capítulo introduz a Inferência Ativa partindo da visão helmholtziana — ou talvez kantiana — da “percepção como inferência inconsciente” (Helmholtz 1867) e ideias relacionadas que surgiram mais recentemente sob a hipótese do cérebro bayesiano. Ele explica como a Inferência Ativa engloba e estende essas ideias tratando não apenas a percepção, mas também a ação, o planejamento e o aprendizado como problemas de inferência (Bayesiana) e derivando uma aproximação baseada em princípios (variacional) para esses problemas de outra forma intratáveis.</p>
</div>
<div id="percepção-como-inferência" class="section level2 hasAnchor" number="2.2">
<h2><span class="header-section-number">2.2</span> Percepção como Inferência<a href="o-caminho-de-baixo-para-a-inferência-ativa.html#percepção-como-inferência" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Há uma longa tradição de ver o cérebro como uma “máquina preditiva”, ou um órgão estatístico que infere e prevê estados externos do mundo. Essa ideia remonta à noção de “percepção como inferência inconsciente” (Helmholtz 1866). Mais recentemente, isso foi reformulado como a hipótese do “cérebro bayesiano” (Doya 2007). A partir dessa perspectiva, a percepção não é uma transdução puramente de baixo para cima de estados sensoriais (por exemplo, da retina) em representações internas do que está lá fora (por exemplo, como padrões de atividade neuronal). Em vez disso, é um processo inferencial que combina informações anteriores (de cima para baixo) sobre as causas mais prováveis ​​das sensações com estímulos sensoriais (de baixo para cima). Os processos inferenciais operam em representações probabilísticas de estados do mundo e seguem a regra de Bayes, que prescreve a atualização (ótima) à luz da evidência sensorial. A percepção não é um processo passivo de fora para dentro – no qual a informação é extraída de impressões em nosso epitélio sensorial de “lá fora”. É um processo construtivo de dentro para fora – no qual as sensações são usadas para confirmar ou refutar hipóteses sobre como elas foram geradas (MacKay 1956, Gregory 1980, Yuille e Kersten 2006, Neisser 2014, A. Clark 2015).</p>
<p>Por sua vez, realizar a inferência Bayesiana requer um modelo generativo – às vezes chamado de modelo direto. Um modelo generativo é uma construção da teoria estatística que gera previsões sobre as observações. Pode ser formulado como a probabilidade conjunta <span class="math inline">\(P({\color{Red}x,\color{Orange}y)}\)</span> das observações <span class="math inline">\(\color{Orange}y\)</span> e os estados ocultos do mundo <span class="math inline">\(\color{Red}x\)</span> que geram essas observações. Estes últimos são referidos como estados ocultos ou latentes, pois não podem ser observados diretamente. Esta probabilidade conjunta pode ser decomposta em duas partes. O primeiro é um <span class="math inline">\(P({\color{Red}x)}\)</span> prévio, que denota o conhecimento do organismo sobre os estados ocultos do mundo antes de ver os dados sensoriais.</p>
<p>A segunda é a probabilidade <span class="math inline">\(P( y | x)\)</span>, que denota o conhecimento do organismo de como as observações são geradas a partir de estados. A regra de Bayes nos diz como combinar esses dois elementos, essencialmente atualizando uma probabilidade anterior <span class="math inline">\(P(x)\)</span> em uma probabilidade posterior de estados ocultos após receber observações <span class="math inline">\(P(x | y)\)</span>. Para os leitores que precisam de uma breve atualização sobre a teoria básica da probabilidade, o <strong>quadro 2.1</strong> fornece um resumo.</p>
<p>A inferência bayesiana é um tópico amplo que surge em disciplinas como estatística, aprendizado de máquina e neurociência computacional. Um tratamento completo dos tópicos associados está além do escopo deste livro, mas há excelentes recursos disponíveis para aqueles que desejam entendê-lo em profundidade (Murphy 2012). No entanto, tudo isso é baseado em uma regra simples. Para ilustrar essa regra, consideramos um exemplo de inferência perceptiva Bayesiana (figura 2.1). Imagine uma pessoa que acredita fortemente que está diante de uma maçã. Essa crença corresponde a uma probabilidade anterior, ou abreviada. Essa priori compreende a probabilidade atribuída à hipótese da maçã e a probabilidade atribuída às hipóteses alternativas. Neste exemplo, nossa hipótese alternativa é que não é uma maçã, mas um sapo. Numericamente, a distribuição de probabilidade anterior atribui 0,9 à maçã e 0,1 à rã. Observe que, como assumimos que existem apenas duas hipóteses plausíveis (mutuamente exclusivas), elas devem somar um. A pessoa também está equipada com um modelo de probabilidade, que atribui uma alta probabilidade ao fato de que os sapos pulam, enquanto as maçãs não. Essa probabilidade especifica o mapeamento (probabilístico) dos dois estados ocultos (sapo ou maçã) para as duas observações (pula ou não pula). Juntos, o anterior e a probabilidade formam o modelo generativo da pessoa.</p>
<table>
<colgroup>
<col width="100%" />
</colgroup>
<thead>
<tr class="header">
<th>Quadro 2.1 As regras de soma e produto de probabilidade</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>O raciocínio probabilístico é sustentado por duas regras principais: as regras de soma e produto de probabilidade, que são as seguintes (respectivamente): <span class="math display">\[\sum_{\color{Red}x} P(\color{Red}x)=1\]</span> <span class="math display">\[P(\color{Red}x)P(\color{Orange}y|\color{Red}x)=P(\color{Red}x,\color{Orange}y)\]</span> A regra da soma diz que a probabilidade de todos os eventos possíveis <span class="math inline">\((x)\)</span> deve somar (ou integrar) a um. A regra do produto diz que a probabilidade conjunta de duas variáveis aleatórias (<span class="math inline">\(x\)</span> e <span class="math inline">\(y\)</span>) pode ser decomposta no produto da probabilidade de uma variável (<span class="math inline">\(P(x)\)</span>) e a probabilidade condicional da segunda variável dada a primeira (<span class="math inline">\(P(y|x)\)</span>). Uma probabilidade condicional é a probabilidade de uma variável (aqui, <span class="math inline">\(y\)</span>) se soubermos o valor que a outra variável (aqui, <span class="math inline">\(x\)</span>) assume. Podemos desenvolver dois resultados importantes a partir dessas regras simples. A primeira é a operação de marginalização. A segunda é a regra de Bayes. A marginalização nos permite obter uma distribuição de apenas uma das duas variáveis de uma distribuição conjunta: <img src="images/quadro2_1-prob_1.png" /> A probabilidade de y é chamada de probabilidade marginal, e nos referimos a essa operação como marginalização de x. A regra de Bayes pode ser obtida diretamente da regra do produto: <img src="images/quadro2_1-prob_2.png" /> Isso nos permite traduzir entre uma distribuição prévia e condicional (verossimilhança) e a marginal associada e a outra distribuição condicional (posterior). Simplificando, a regra de Bayes apenas diz que a probabilidade de duas coisas é a probabilidade da primeira, dada a segunda, vezes a probabilidade da segunda, que é o mesmo que a probabilidade da segunda, dada a primeira, vezes a probabilidade do primeiro.</td>
</tr>
</tbody>
</table>
<p>Agora imagine que a pessoa observa que seu sapo-maçã pula. A regra de Bayes nos diz como formar uma crença posterior a partir da anterior, levando em conta a probabilidade de pular. Essa regra é expressa da seguinte forma:</p>
<p><span class="math display">\[P(x|y)=\frac{P(x)P(y|x)}{P(y)}\]</span></p>
<div class="figure">
<img src="images/Figura2_1.png" alt="" />
<p class="caption"><strong>Figura 2.1</strong> Um exemplo simples de inferência Bayesiana. Superior esquerdo: A crença prévia P(x) do organismo sobre o objeto que ele verá, antes de ter feito qualquer observação, ou seja, uma distribuição categórica sobre duas possibilidades, maçã (com probabilidade 0,9) e sapo (com probabilidade 0,1). Superior direito: A crença posterior do organismo P(x | y ) após observar que o objeto salta. Crenças posteriores podem ser calculadas usando a regra de Bayes sob uma função de verossimilhança P( y | x). Isso é mostrado abaixo do anterior e do posterior e específica que, se o objeto for uma maçã, há uma probabilidade muito pequena (0,01) de que ele pule, enquanto se for um sapo, a probabilidade de pular é muito maior ( 0,81). (As barras de probabilidade nesta figura não estão exatamente em escala.) Neste caso específico, a atualização de anterior para posterior é grande.</p>
</div>
<p>Sob o modelo de verossimilhança da figura 2.1, a probabilidade posterior atribuída ao sapo é 0,9 e a probabilidade atribuída à maçã é 0,1. Conforme destacado no quadro 2.1, o denominador da equação 2.1 pode ser calculado marginalizando o numerador. Usando nosso exemplo do sapo-maçã, aproveitamos a oportunidade para descompactar duas noções diferentes de surpresa — ambas importantes na Inferência Ativa. A primeira, a que nos referimos simplesmente como surpresa, é a evidência logarítmica negativa, onde a evidência é a probabilidade marginal das observações. Em nosso exemplo, esta é a probabilidade logarítmica negativa de observar qualquer coisa saltando sob o modelo generativo. A surpresa é uma quantidade muito importante do ponto de vista bayesiano. É uma medida de quão mal um modelo se ajusta aos dados que tenta explicar. Para colocar isso intuitivamente, podemos calcular a probabilidade do comportamento observado (pulo) sob nosso modelo. Lembre-se de que isso atribui uma probabilidade a priori muito alta às maçãs e uma probabilidade a priori baixa às rãs. Assim, nossa probabilidade marginal de pular é a seguinte:</p>
<p><img src="images/Prob%20Sapos%20Ma%C3%A7as.png" /></p>
<p>Isso significa que, sob esse modelo, esperaríamos observar o comportamento de pulor cerca de 9 vezes em 100 observações. Como tal, deveríamos nos surpreender ao observar isso se subscrevermos o modelo da figura 2.1. Podemos quantificar isso em termos de surpresa <span class="math inline">\((ℑ)\)</span>. Isso é dado por <span class="math inline">\(ℑ(y=pular) = −lnP(y=pular) = −ln(0,09) = 2,4 nats\)</span> <a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a> . Quanto maior esse número, pior o modelo como explicação adequada para as observações em questão. Isso nos permite comparar modelos em relação aos dados. Por exemplo, considere um modelo alternativo, onde temos uma crença prévia de que os sapos são vistos 100% do tempo. Seguindo os mesmos passos da equação 2.2, calculamos uma surpresa de cerca de 0,2 nats. Este é um modelo melhor desses dados, pois a observação é muito menos surpreendente. O procedimento de pontuação de modelos com base em suas evidências (ou surpresa) é frequentemente chamado de comparação de modelos bayesianos. Para modelos mais complicados, a forma da surpresa pode não ser tão simples.</p>
<p>A <strong>Tabela 2.1</strong> fornece a forma da surpresa (omitindo constantes) para uma série de distribuições de probabilidade – além da probabilidade categórica em nosso exemplo. Crucialmente, isso nos permite falar sobre surpresa para distribuições de probabilidade cujo suporte<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a> difere do exemplo simples usado aqui. Isso é importante porque a maneira pela qual os dados sensoriais são gerados pelo mundo varia com o tipo de dados. Podemos nos surpreender ao encontrar o rosto de alguém que não esperávamos ver (distribuição categórica), ou podemos nos surpreender por estar mais frio do lado de fora do que prevíamos (distribuição contínua). A Tabela 2.1 pode ser vista como um portfólio das distribuições de probabilidade à nossa disposição quando passamos a construir modelos generativos em capítulos subsequentes. De maneira mais geral, ele afirma que a surpresa é um conceito que pode ser avaliado para qualquer família de distribuições de probabilidade.</p>
<p><strong>Tabela 2.1 Distribuições de probabilidade e surpresa<a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a></strong></p>
<table>
<colgroup>
<col width="27%" />
<col width="45%" />
<col width="27%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">Distribuição</th>
<th align="center">Suporte</th>
<th align="center">Surpresa<span class="math inline">\((ℑ)\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Gaussiana<a href="#fn6" class="footnote-ref" id="fnref6"><sup>6</sup></a></td>
<td align="center"><span class="math inline">\(x\in\mathbb{R}\)</span></td>
<td align="center"><span class="math inline">\(\frac{1}{2}(x-\mu)\prod(x-\mu)\)</span></td>
</tr>
<tr class="even">
<td align="center">Multinomial</td>
<td align="center"><span class="math display">\[x_{i}\in\left ( 0,\cdots, N \right )\]</span> <span class="math display">\[{i}\in\left \{ 1 , \cdots , K \right \}\]</span> <span class="math display">\[\sum_i{x_i}=N\]</span></td>
<td align="center"><span class="math display">\[-\sum_i{x_i}\ln d_i\]</span></td>
</tr>
<tr class="odd">
<td align="center">Dirichlet<a href="#fn7" class="footnote-ref" id="fnref7"><sup>7</sup></a></td>
<td align="center"><span class="math display">\[x_{i}\in\left ( 0,1 \right )\]</span> <span class="math display">\[{i}\in\left \{ 1 , \cdots , K \right \}\]</span> <span class="math display">\[\sum_i{x_i}=1\]</span></td>
<td align="center"><span class="math inline">\(\sum(1 - \alpha_i)\ln(x_i)\)</span></td>
</tr>
<tr class="even">
<td align="center">Gamma</td>
<td align="center"><span class="math inline">\(x\in(0,\infty)\)</span></td>
<td align="center"><span class="math inline">\((bx+(1-a)\ln x)\)</span></td>
</tr>
</tbody>
</table>
<p>A segunda noção de surpresa é (um pouco confusa) referida como surpresa bayesiana. Esta é uma medida de quanto temos que atualizar nossas crenças após uma observação. Em outras palavras, a surpresa Bayesiana quantifica a diferença entre uma probabilidade anterior e uma posterior. Isso levanta a questão de como quantificamos a dissimilaridade de duas distribuições de probabilidade.</p>
<p>Uma resposta, da teoria da informação, é usar uma divergência de Kullback-Leibler (KL). Isso é definido como a diferença média entre duas probabilidades logarítmicas</p>
<p><span class="math inline">\(D_{KL}[Q(x)||P(x)] \overset{\Delta}{=} \mathbb{E_{Q(x)}}[\ln{Q(x)} - \ln{P(x)}] \quad\quad\quad\quad\quad\quad\quad\quad\quad\quad \text{(2.3)}\)</span></p>
<p>O símbolo <span class="math inline">\(\mathbb{E}\)</span> aqui indica uma média (ou expectativa) conforme descrito no <strong>quadro 2.2</strong>. Usando o KL-Divergence, podemos quantificar a surpresa Bayesiana do nosso exemplo:</p>
<p><img src="images/Surpresa%20Sapos%20Ma%C3%A7as.png" /></p>
<p>Isso pontua a quantidade de atualização de crenças, em oposição a simplesmente quão improvável era a observação. Para destacar a distinção entre surpresa e surpresa bayesiana, considere o que acontece se nos comprometermos com uma crença prévia de que sempre veremos maçãs. A surpresa bayesiana será zero, já que o prior está tão confiante que não o atualizamos seguindo nossas observações. No entanto, a surpresa é muito grande (4,6 nats), pois é altamente improvável que uma maçã salte.</p>
<table>
<colgroup>
<col width="100%" />
</colgroup>
<thead>
<tr class="header">
<th align="left"><strong>Quadro 2.2 Expectativas</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">É útil referir-se à expectativa de uma variável aleatória <span class="math inline">\(x\)</span>, geralmente denotada por <span class="math inline">\(\mathbb{E[x]}\)</span>. Esta é a média ponderada de todos os valores que a variável pode assumir, ponderada pela sua probabilidade. Para variáveis aleatórias discretas (que só podem receber um número contável de valores possíveis), isso é dado por uma soma ponderada: <span class="math display">\[\mathbb{E(x)}=\sum_x{xP(x)}\]</span> Por exemplo, para uma variável discreta (numérica) que só pode assumir dois valores (1 e 2) com igual probabilidade de <span class="math inline">\(\frac{1}{2}\)</span>, isto é <span class="math inline">\(\mathbb{E(x)}=1*\frac{1}{2}+2*\frac{1}{2}=\frac{3}{2}\)</span>. Para variáveis aleatórias contínuas (que podem ter infinitos valores), as somas são substituídas por integrais. As expectativas também podem ser aplicadas a funções de variáveis aleatórias, em oposição às variáveis diretamente. Por exemplo, se tivermos uma função f (x), onde x tem alguma distribuição contínua, a expectativa é definida como segue: <span class="math display">\[\mathbb{E[f(x)]}=\int_{}^{} f(x)p(x)\, dx\]</span>Usaremos essa notação ao longo deste livro, onde a função <span class="math inline">\(f (x)\)</span> será frequentemente uma probabilidade logarítmica ou razão de probabilidade logarítmica.</td>
</tr>
<tr class="even">
<td align="left"></td>
</tr>
</tbody>
</table>
<p>Observe que, embora tenhamos ilustrado a inferência bayesiana com base em um modelo generativo muito simples, ela se aplica a modelos generativos de qualquer complexidade. No capítulo 4, destacaremos duas formas de modelo generativo que subscrevem a maioria das aplicações em Inferência Ativa.</p>
</div>
<div id="inferência-biológica-e-otimização" class="section level2 hasAnchor" number="2.3">
<h2><span class="header-section-number">2.3</span> Inferência Biológica e Otimização<a href="o-caminho-de-baixo-para-a-inferência-ativa.html#inferência-biológica-e-otimização" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Há dois pontos importantes que conectam o esquema inferencial acima às teorias biológicas e psicológicas da percepção. Primeiro, o procedimento inferencial discutido requer a interação de processos de cima para baixo que codificam previsões (a partir do anterior) e processos de baixo para cima que codificam observações sensoriais (mediadas pela probabilidade). Essa interação de processos de cima para baixo e de baixo para cima distingue a visão inferencial de abordagens alternativas que consideram apenas processos de baixo para cima. Além disso, é central nos tratamentos biológicos modernos da percepção, como a codificação preditiva (discutida no capítulo 4), que é uma implementação algorítmica específica (ou em nível de processo) do esquema de inferência mais geral (bayesiano) discutido aqui.</p>
<p>Em segundo lugar, a inferência Bayesiana é ótima. A otimalidade é definida em relação a uma função de custo que é otimizada (ou seja, minimizada), que, por inferência Bayesiana, é conhecida como energia livre variacional – intimamente relacionada à surpresa. Voltamos a isso na seção 2.5. Ao considerar explicitamente a distribuição completa sobre os estados ocultos, ele lida naturalmente com a incerteza, evitando as limitações de abordagens alternativas que consideram apenas estimativas pontuais de estados ocultos (por exemplo, o valor médio de x). Uma dessas alternativas seria a estimativa de máxima verossimilhança, que simplesmente seleciona o estado oculto mais provável de ter gerado os dados disponíveis. O problema com isso é que tais estimativas ignoram tanto a plausibilidade prévia do estado oculto quanto a incerteza em torno da estimativa. A inferência bayesiana não sofre essas limitações. No entanto, apesar do uso da surpresa para avaliar objetivamente se o modelo é adequado ao propósito, é importante apreciar que a inferência em si é subjetiva. Os resultados da inferência não são necessariamente precisos em nenhum sentido objetivo (ou seja, a crença do organismo pode não corresponder à realidade) por pelo menos duas razões importantes. Primeiro, as criaturas biológicas operam com base em recursos computacionais e energéticos limitados, que tornam a inferência Bayesiana exata intratável<a href="#fn8" class="footnote-ref" id="fnref8"><sup>8</sup></a> . Isso requer aproximações que excluem garantias de otimalidade Bayesiana exata. Essas aproximações incluem a noção de uma posterior variacional - baseada em algo chamado aproximação de campo médio - que é central para o capítulo 4.</p>
<p>A segunda razão pela qual a otimalidade pode ser pensada como subjetiva é que os organismos operam com base no modelo generativo de um sujeito de como suas observações são geradas, o que pode ou não corresponder ao processo generativo real que gera suas observações. Isso não quer dizer que o modelo generativo deva corresponder ao processo generativo. De fato, pode haver modelos que forneçam explicações melhores (por exemplo, mais simples) dos dados disponíveis do que os processos que realmente os geraram – conforme quantificado por sua relativa surpresa. Um bom exemplo disso são as ilusões, para as quais alguém encontra uma explicação mais simples para sua entrada visual em relação a como os estímulos visuais foram cuidadosamente projetados por um psicofísico malicioso.</p>
<p>O próprio modelo generativo pode ser otimizado à medida que novas experiências são adquiridas. Isso pode ou não convergir para o processo generativo.</p>
<p>A <strong>Figura 2.2</strong> ilustra esse ponto e a diferença entre as verdadeiras contingências ambientais, ou o processo generativo, que é inacessível ao organismo e o modelo generativo do organismo do mundo. Neste exemplo em particular, o processo generativo está em um verdadeiro estado x* que é inacessível ao organismo. No entanto, o organismo e o mundo estão mutuamente acoplados, e x* gera uma observação y, que o organismo sente. O organismo pode usar esta observação y e a regra de Bayes para inferir a (probabilidade posterior de ) alguma variável explicativa ou estado oculto no modelo generativo. Na figura, nos referimos a x* e x como estados ocultos, enfatizando que nenhum deles é observável. No entanto, eles são sutilmente diferentes: o primeiro faz parte do modelo generativo do organismo, enquanto o último faz parte do processo generativo e inacessível ao organismo. Além disso, x* e x não vivem necessariamente no mesmo espaço. Pode ser que os estados ocultos no mundo externo assumam valores que estão fora do espaço de explicações disponíveis ao cérebro. Por outro lado, pode ser que as explicações do cérebro incluam variáveis ​​que não existem no mundo exterior. Por exemplo, o primeiro pode ser de 5 dimensões e o último de 2 dimensões, ou um pode ser contínuo e o outro categórico.</p>

</div>
</div>
<div class="footnotes">
<hr />
<ol start="3">
<li id="fn3"><p>Como bits, nats são unidades de informação. A escolha da unidade depende se usamos um logaritmo de base 2 (bits) ou um logaritmo natural (nats).<a href="o-caminho-de-baixo-para-a-inferência-ativa.html#fnref3" class="footnote-back">↩︎</a></p></li>
<li id="fn4"><p>Suporte é um termo técnico que se refere aos argumentos possíveis para uma distribuição. Por exemplo, o suporte de uma distribuição de probabilidade categórica é uma série de estados alternativos (isto é, espaço de eventos) cuja probabilidade pode ser quantificada. O suporte de uma distribuição normal univariada é toda a reta numérica real.<a href="o-caminho-de-baixo-para-a-inferência-ativa.html#fnref4" class="footnote-back">↩︎</a></p></li>
<li id="fn5"><p>Os detalhes desta tabela não são importantes para entender conceitualmente a Inferência Ativa, mas para leitores interessados, descompactamos brevemente os pontos-chave. A coluna Suporte nos informa o conjunto de variáveis cuja surpresa pode ser quantificada usando cada distribuição. Este é o conjunto de números reais para a distribuição gaussiana. Para a distribuição multinomial, o suporte compreende um grupo de K variáveis, cada uma assumindo um valor inteiro até um máximo N, sob a restrição de que todos os elementos desse grupo somam N. Para a distribuição de Dirichlet, o suporte inclui qualquer grupo de K números reais entre 0 e 1, onde todos os elementos do grupo somam 1. A distribuição gama quantifica a surpresa de números reais não negativos. A coluna Surpresa mostra como a surpresa pode ser calculada. Isso depende de constantes (além da variável aleatória x) que controlam a forma da distribuição subjacente.<a href="o-caminho-de-baixo-para-a-inferência-ativa.html#fnref5" class="footnote-back">↩︎</a></p></li>
<li id="fn6"><p>Casos especiais incluem distribuições categóricas <span class="math inline">\((K  &gt; 2, N  =  1)\)</span>, binomial <span class="math inline">\((K  = 2, N  &gt;  1)\)</span> e Bernoulli <span class="math inline">\((K = 2, N  =  1)\)</span><a href="o-caminho-de-baixo-para-a-inferência-ativa.html#fnref6" class="footnote-back">↩︎</a></p></li>
<li id="fn7"><p>Um caso especial é a distribuição beta <span class="math inline">\((K=2)\)</span><a href="o-caminho-de-baixo-para-a-inferência-ativa.html#fnref7" class="footnote-back">↩︎</a></p></li>
<li id="fn8"><p>Curiosamente, as limitações de recursos não são a única barreira para a inferência Bayesiana exata. Na presença de modelos complexos, a inferência exata pode ser analiticamente intratável, de modo que nenhum recurso adicional poderia ajudar a resolver o problema exato.<a href="o-caminho-de-baixo-para-a-inferência-ativa.html#fnref8" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="visão-geral.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="dicionário.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Inferencia Ativa.pdf", "Inferencia Ativa.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
